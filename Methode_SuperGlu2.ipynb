{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bdaf92",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a99ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x29f663884c8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import csv\n",
    "\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import ProjectiveTransform\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "\n",
    "from models.matching import Matching\n",
    "\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78156c",
   "metadata": {},
   "source": [
    "## Parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf5d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will resize to 640x480 (WxH)\n",
      "Running inference on device \"cpu\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "# Parametres\n",
    "\n",
    "cache=False\n",
    "eval=False\n",
    "fast_viz=False\n",
    "force_cpu=False\n",
    "input_dir='assets/pair/'\n",
    "input_pairs='assets/pair.txt'\n",
    "keypoint_threshold=0.005\n",
    "match_threshold=0.2\n",
    "max_keypoints=1024\n",
    "max_length=-1\n",
    "nms_radius=4\n",
    "opencv_display=False\n",
    "output_dir='resultat'\n",
    "resize=[640, 480]\n",
    "resize_float=False\n",
    "show_keypoints=False\n",
    "shuffle=False\n",
    "sinkhorn_iterations=20\n",
    "superglue='outdoor'\n",
    "viz=True\n",
    "viz_extension='jpg'\n",
    "\n",
    "if (len(resize) == 2) and (resize[1] == -1):    \n",
    "    resize = resize[0:1]\n",
    "if len(resize) == 2:\n",
    "    print('Will resize to {}x{} (WxH)'.format(\n",
    "        resize[0], resize[1]))\n",
    "elif len(resize) == 1 and resize[0] > 0:\n",
    "    print('Will resize max dimension to {}'.format(resize[0]))\n",
    "elif len(resize) == 1:\n",
    "    print('Will not resize images')\n",
    "else:\n",
    "    raise ValueError('Cannot specify more than two integers for --resize')\n",
    "    \n",
    "# Load the SuperPoint and SuperGlue models.\n",
    "device = 'cuda' if torch.cuda.is_available() and not force_cpu else 'cpu'\n",
    "print('Running inference on device \\\"{}\\\"'.format(device))\n",
    "config = {\n",
    "    'superpoint': {\n",
    "        'nms_radius': nms_radius,\n",
    "        'keypoint_threshold': keypoint_threshold,\n",
    "        'max_keypoints': max_keypoints\n",
    "    },\n",
    "    'superglue': {\n",
    "        'weights': superglue,\n",
    "        'sinkhorn_iterations': sinkhorn_iterations,\n",
    "        'match_threshold': match_threshold,\n",
    "    }\n",
    "}\n",
    "\n",
    "matching = Matching(config).eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bc76c",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35017750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filteringBlackAreaKeypoints(img,keypoints,keypoints1):\n",
    "    new_keypoints = [[1,1]]\n",
    "    new_keypoints1 = [[1,1]]\n",
    "    \n",
    "#     print('img.shape', img.shape)\n",
    "    \n",
    "    #print('keypoints : ',keypoints)\n",
    "\n",
    "    for i in range(len(keypoints)):\n",
    "        kpt_x = int(keypoints[i][0])\n",
    "        kpt_y = int(keypoints[i][1])\n",
    "        img_kpt = img[(kpt_y-2):(kpt_y+3),(kpt_x-2):(kpt_x+3)]\n",
    "        \n",
    "        nbr_zeros=0\n",
    "        \n",
    "        for m in range(img_kpt.shape[0]):\n",
    "            for n in range(img_kpt.shape[1]):\n",
    "                if(img_kpt[m,n]==0):\n",
    "                    nbr_zeros += 1\n",
    "                                \n",
    "#         sum_masque = np.sum(img_kpt)\n",
    "#         print('sum : ',sum_masque)\n",
    "#         if(sum_masque >  2000):\n",
    "        #print('nbr_zeros :',nbr_zeros)\n",
    "        if (nbr_zeros<1):\n",
    "#             plt.figure(figsize=(10, 10))\n",
    "#             plt.imshow(img_kpt)\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "            #print(img_kpt)\n",
    "            new_keypoints = np.concatenate((new_keypoints,[keypoints[i]]),axis=0)\n",
    "            new_keypoints1 = np.concatenate((new_keypoints1,[keypoints1[i]]),axis=0)\n",
    "        \n",
    "    #print('new_keypoints[1:] : ',new_keypoints[1:])\n",
    "            \n",
    "    return new_keypoints[1:],new_keypoints1[1:]\n",
    "\n",
    "def process_resize(w, h, resize):\n",
    "    assert(len(resize) > 0 and len(resize) <= 2)\n",
    "    if len(resize) == 1 and resize[0] > -1:\n",
    "        scale = resize[0] / max(h, w)\n",
    "        w_new, h_new = int(round(w*scale)), int(round(h*scale))\n",
    "    elif len(resize) == 1 and resize[0] == -1:\n",
    "        w_new, h_new = w, h\n",
    "    else:  # len(resize) == 2:\n",
    "        w_new, h_new = resize[0], resize[1]\n",
    "\n",
    "    # Issue warning if resolution is too small or too large.\n",
    "    if max(w_new, h_new) < 160:\n",
    "        print('Warning: input resolution is very small, results may vary')\n",
    "    elif max(w_new, h_new) > 2000:\n",
    "        print('Warning: input resolution is very large, results may vary')\n",
    "\n",
    "    return w_new, h_new\n",
    "\n",
    "def frame2tensor(frame, device):\n",
    "    return torch.from_numpy(frame/255.).float()[None, None].to(device)\n",
    "\n",
    "def crop_image(img,xC,yC,sizeX,sizeY):\n",
    "    #y,x,z = img.shape\n",
    "    startx = xC - sizeX//2\n",
    "    starty = yC - sizeY//2  \n",
    "    \n",
    "    img_out = img[starty:(starty+sizeY),startx:(startx+sizeX),:]\n",
    "    \n",
    "    while(img_out.shape[0] == 0 or img_out.shape[1]==0):\n",
    "        sizeX = sizeX - 20        \n",
    "        sizeY = sizeY - 20\n",
    "        startx = xC - sizeX//2\n",
    "        starty = yC - sizeY//2\n",
    "        img_out = img[starty:(starty+sizeY),startx:(startx+sizeX),:]\n",
    "    \n",
    "    return img_out,sizeX1\n",
    "\n",
    "def read_image2(image_int, device, resize, rotation, resize_float):\n",
    "    image = cv2.cvtColor(image_int, cv2.COLOR_BGR2GRAY)\n",
    "    if image is None:\n",
    "        return None, None, None\n",
    "    w, h = image.shape[1], image.shape[0]\n",
    "    w_new, h_new = process_resize(w, h, resize)\n",
    "    scales = (float(w) / float(w_new), float(h) / float(h_new))\n",
    "\n",
    "    if resize_float:\n",
    "        image = cv2.resize(image.astype('float32'), (w_new, h_new))\n",
    "    else:\n",
    "        image = cv2.resize(image, (w_new, h_new)).astype('float32')\n",
    "\n",
    "    if rotation != 0:\n",
    "        image = np.rot90(image, k=rotation)\n",
    "        if rotation % 2:\n",
    "            scales = scales[::-1]\n",
    "\n",
    "    inp = frame2tensor(image, device)\n",
    "    return image, inp, scales\n",
    "\n",
    "def get_matrice_transformation(image0_frag,image1_fre,rotation,device,resize,resize_float,do_viz,Tx,Ty,sizeX1):\n",
    "    image0, inp0 , scales0 = read_image2(\n",
    "        image0_frag , device, resize, 0, resize_float)\n",
    "    image1, inp1, scales1 = read_image2(\n",
    "        image1_fre , device, resize, 0, resize_float)\n",
    "    \n",
    "    fact_i_0 = image0_frag.shape[0] / image0.shape[0]\n",
    "    fact_j_0 = image0_frag.shape[1] / image0.shape[1]\n",
    "    \n",
    "    fact_i_1 = image1_fre.shape[0] / image1.shape[0]\n",
    "    fact_j_1 = image1_fre.shape[1] / image1.shape[1]\n",
    "    \n",
    "    \n",
    "    # Perform the matching.\n",
    "    pred = matching({'image0': inp0, 'image1': inp1})\n",
    "    pred = {k: v[0].cpu().numpy() for k, v in pred.items()}\n",
    "    kpts0, kpts1 = pred['keypoints0'], pred['keypoints1']\n",
    "    matches, conf = pred['matches0'], pred['matching_scores0']\n",
    "    \n",
    "    # Keep the matching keypoints.\n",
    "    valid = matches > -1\n",
    "    mkpts0 = kpts0[valid]\n",
    "    mkpts1 = kpts1[matches[valid]]\n",
    "    mconf = conf[valid]\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image0,cmap='gray')\n",
    "    plt.plot(mkpts0[:, 0], mkpts0[:, 1], \"og\", markersize=5)  # og:shorthand for green circle\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    '''\n",
    "    mkpts0, mkpts1 = filteringBlackAreaKeypoints(image0,mkpts0,mkpts1)\n",
    "    \n",
    "    nbr_matches = len( mkpts0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if ( len(mkpts0) < 3  ):\n",
    "        #print('Error : not enough matches, {} matches'.format(len(mkpts0)))\n",
    "        return -1,0,0, False\n",
    "\n",
    "    \n",
    "\n",
    "    #print(mkpts0.shape)\n",
    "    #print(len(mkpts0))\n",
    "        \n",
    "    \n",
    "    mkpts0[:, 1] *= fact_i_0\n",
    "    mkpts0[:, 0] *= fact_j_0\n",
    "    \n",
    "    mkpts1[:, 1] *= fact_i_1\n",
    "    mkpts1[:, 0] *= fact_j_1\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image0_frag,cmap='gray')\n",
    "    plt.plot(mkpts0[:, 0], mkpts0[:, 1], \"og\", markersize=5)  # og:shorthand for green circle\n",
    "    plt.axis('off')\n",
    "    plt.show()   \n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image1_fre,cmap='gray')\n",
    "    plt.plot(mkpts1[:, 0], mkpts1[:, 1], \"og\", markersize=5)  # og:shorthand for green circle\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    startx = Tx - sizeX1//2 \n",
    "    starty = Ty - sizeY1//2\n",
    "    \n",
    "    #print(starty,startx)\n",
    "    #print(image_original.shape)\n",
    "    \n",
    "    mkpts1[:, 0] += startx\n",
    "    mkpts1[:, 1] += starty\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_original[(int(mkpts1[1, 0]-n)):(int(mkpts1[1, 0]+n+1)),(int(mkpts1[1, 1])-n):(int(mkpts1[1, 1])+n+1)])\n",
    "    plt.axis('off')\n",
    "    plt.show() \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #print(mkpts0)\n",
    "    L_y, L_x , L_z  = image0_frag.shape\n",
    "    copy_mkpts0 = np.copy(mkpts0)\n",
    "    if (rotation == 90):\n",
    "        #image0_frag_rot = np.rot90(image0_frag)\n",
    "        #print(copy_mkpts0)\n",
    "        mkpts0[:, 0] = L_x - copy_mkpts0[:, 1]\n",
    "        mkpts0[:, 1] = copy_mkpts0[:, 0] \n",
    "    elif (rotation == 180):\n",
    "        #print(copy_mkpts0)\n",
    "        #image0_frag_rot = np.rot90(image0_frag)\n",
    "        #image0_frag_rot = np.rot90(image0_frag_rot)\n",
    "        mkpts0[:, 0] = L_x - copy_mkpts0[:, 0]\n",
    "        mkpts0[:, 1] = L_y - copy_mkpts0[:, 1] \n",
    "    elif (rotation == 270):\n",
    "        #image0_frag_rot = np.rot90(image0_frag)\n",
    "        #image0_frag_rot = np.rot90(image0_frag_rot)\n",
    "        #image0_frag_rot = np.rot90(image0_frag_rot)\n",
    "        #print(copy_mkpts0)\n",
    "        mkpts0[:, 0] = copy_mkpts0[:, 1]\n",
    "        mkpts0[:, 1] = L_y - copy_mkpts0[:, 0] \n",
    "    \n",
    "    #print(image_original[int(mkpts1[0, 1]),int(mkpts1[0, 0]),:])\n",
    "    #print(np.where(image_original[(int(mkpts1[1, 0]-5)):(int(mkpts1[1, 0]+6)),(int(mkpts1[1, 1])-5):(int(mkpts1[1, 1])+6)] == a))\n",
    "    '''\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    plt.imshow(image_original)\n",
    "    plt.plot(mkpts1[:, 0], mkpts1[:, 1], \"og\", markersize=1)  # og:shorthand for green circle\n",
    "    plt.axis('off')\n",
    "    plt.show()  \n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    #model1, inliers = ransac(\n",
    "    #    (mkpts0, mkpts1),\n",
    "    #    ProjectiveTransform, min_samples=4,\n",
    "    #    residual_threshold=4, max_trials=10000\n",
    "    #)\n",
    "    \n",
    "    #print('model1',model1)\n",
    "    \n",
    "    #print('inliers',inliers)\n",
    "    \n",
    "    \n",
    "    transformation_matrix, rigid_mask = cv2.estimateAffinePartial2D(mkpts0, mkpts1)\n",
    "    \n",
    "    inliers = np.transpose(rigid_mask[:] ==1 )[0]\n",
    "    \n",
    "    #print('transformation_rigid_matrix',transformation_rigid_matrix)\n",
    "    #print(transformation_rigid_matrix[1,2])\n",
    "    \n",
    "    #print('rigid_mask',np.transpose(rigid_mask[:] ==1 )[0])\n",
    "    \n",
    "    n_inliers = np.sum(inliers)\n",
    "    #print('Nbr Matches apres filtrage :',len( mkpts0))\n",
    "    #print('Number of inliers: %d.' % n_inliers)\n",
    "    \n",
    "    if ( n_inliers < 3  ):\n",
    "        #print('Error : not enough matches, {} matches'.format(len(mkpts0)))\n",
    "        return -1,0,0, False\n",
    "    \n",
    "    if do_viz:\n",
    "        n_inliers = np.sum(inliers)\n",
    "        print('Number of inliers: %d.' % n_inliers)\n",
    "        inlier_keypoints_left = [cv2.KeyPoint(point[0], point[1], 1) for point in mkpts0[inliers]]\n",
    "        inlier_keypoints_right = [cv2.KeyPoint(point[0], point[1], 1) for point in mkpts1[inliers]]\n",
    "        placeholder_matches = [cv2.DMatch(idx, idx, 5) for idx in range(n_inliers)]\n",
    "\n",
    "\n",
    "        image_r1 = cv2.drawMatches(image0_frag, inlier_keypoints_left, image_original, inlier_keypoints_right, placeholder_matches, None)\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image_r1)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    #print(transformation_matrix)\n",
    "    '''\n",
    "    T_x = transformation_matrix[0,2]\n",
    "    T_y = transformation_matrix[1,2]\n",
    "    rot = - np.angle(transformation_matrix[0,0]+transformation_matrix[1,0]*1j)*180/np.pi\n",
    "    \n",
    "    if rot > 0 :\n",
    "        rot=rot-360\n",
    "    \n",
    "\n",
    "    \n",
    "    tx = -T_y + L_x*np.sin(rot*np.pi/180)/2 - L_y*np.cos(rot*np.pi/180)/2\n",
    "    ty = -T_x - L_x*np.cos(rot*np.pi/180)/2 - L_y*np.sin(rot*np.pi/180)/2\n",
    "    '''\n",
    "    #print('Transltation : (',T_x,',', T_y,')')\n",
    "    #print('Rotation : ', rot)\n",
    "    \n",
    "    bool_accompli = True\n",
    "    \n",
    "    return transformation_matrix, nbr_matches , n_inliers, bool_accompli\n",
    "    \n",
    "    \n",
    "\n",
    "def get_transformation(image0_frag,image1_fre,device,resize,resize_float,do_viz,Tx,Ty,sizeX1):\n",
    "    \n",
    "    rotation = 0    \n",
    "    transformation_matrix_0, nbr_matches_0 , nbr_inliers_0,bool_accompli_0 = get_matrice_transformation(image0_frag,image1_fre,rotation,device,resize,resize_float,do_viz,Tx,Ty,sizeX1)\n",
    "    #print('Transltation : (',T_x_0,',', T_y_0,')')\n",
    "    #print('Rotation : ', rot_0)\n",
    "    \n",
    "    \n",
    "    #print('######################## ROTATION : 90 ################')    \n",
    "    image0_frag = np.rot90(image0_frag)\n",
    "    rotation = 90\n",
    "    transformation_matrix_90, nbr_matches_90 , nbr_inliers_90,bool_accompli_90 = get_matrice_transformation(image0_frag,image1_fre,rotation,device,resize,resize_float,do_viz,Tx,Ty,sizeX1)   \n",
    "    #print('Transltation : (',T_x_90,',', T_y_90,')')\n",
    "    #print('Rotation : ', rot_90)\n",
    "    \n",
    "    \n",
    "    #print('################ ROTATION : 180 ################')\n",
    "    image0_frag = np.rot90(image0_frag)\n",
    "    rotation = 180\n",
    "    transformation_matrix_180, nbr_matches_180 , nbr_inliers_180,bool_accompli_180 = get_matrice_transformation(image0_frag,image1_fre,rotation,device,resize,resize_float,do_viz,Tx,Ty,sizeX1)    \n",
    "    #print('Transltation : (',T_x_180,',', T_y_180,')')\n",
    "    #print('Rotation : ', rot_180)\n",
    "    \n",
    "    \n",
    "    #print('################ ROTATION : 270 ####################')\n",
    "    image0_frag = np.rot90(image0_frag)\n",
    "    rotation = 270\n",
    "    transformation_matrix_270, nbr_matches_270 , nbr_inliers_270,bool_accompli_270 = get_matrice_transformation(image0_frag,image1_fre,rotation,device,resize,resize_float,do_viz,Tx,Ty,sizeX1)    \n",
    "    #print('Transltation : (',T_x_270,',', T_y_270,')')\n",
    "    #print('Rotation : ', rot_270)\n",
    "    \n",
    "    #rotations = np.array([rot_0,rot_90,rot_180,rot_270])\n",
    "    #T_x_t = np.array([T_x_0,T_x_90,T_x_180,T_x_270])\n",
    "    #T_y_t = np.array([T_y_0,T_y_90,T_y_180,T_y_270])\n",
    "    nbr_matches_t = np.array([nbr_matches_0,nbr_matches_90,nbr_matches_180,nbr_matches_270])\n",
    "    nbr_inliers_t = np.array([nbr_inliers_0,nbr_inliers_90,nbr_inliers_180,nbr_inliers_270])\n",
    "    \n",
    "    #print(rotations)\n",
    "    #print(T_x_t)\n",
    "    #print(T_y_t)\n",
    "    #print(nbr_matches_t)\n",
    "    #print(nbr_inliers_t)\n",
    "    \n",
    "    index_resultat =-1\n",
    "    \n",
    "    if(bool_accompli_0 == False and bool_accompli_90 == False and bool_accompli_180 == False and bool_accompli_270 == False ):\n",
    "        print('Error: Pas possible de trouver Matrice de rotation')\n",
    "        return 'Nan','Nan','Nan'\n",
    "    else:\n",
    "        nbr_inliers_max = np.max(nbr_inliers_t)\n",
    "        nbr_inliers_max_index = np.where(nbr_inliers_t == nbr_inliers_max)\n",
    "        #print('len(nbr_inliers_max_index[0])',len(nbr_inliers_max_index[0]))\n",
    "        \n",
    "        if(len(nbr_inliers_max_index[0]) > 1 ):\n",
    "            nbr_matches_t[np.where(nbr_inliers_t != nbr_inliers_max)[0]] = 0\n",
    "            #print('nbr_matches_t',nbr_matches_t)\n",
    "            nbr_matches_max = np.max(nbr_matches_t)\n",
    "            #print('nbr_matches_max',nbr_matches_max)\n",
    "            nbr_matches_max_index = np.where(nbr_matches_t == nbr_matches_max)\n",
    "            #print('nbr_matches_max_index',nbr_matches_max_index)            \n",
    "            index_resultat = nbr_matches_max_index[0][0] \n",
    "            #print('nbr_matches_max_index',nbr_matches_max_index)\n",
    "        else:\n",
    "            index_resultat = nbr_inliers_max_index[0][0]\n",
    "            \n",
    "    #Tx = T_x_t[index_resultat]\n",
    "    #Ty = T_y_t[index_resultat]\n",
    "    #rot = rotations[index_resultat]\n",
    "    if(index_resultat == 0):\n",
    "        matrice_correct = transformation_matrix_0\n",
    "    elif(index_resultat == 1):\n",
    "        matrice_correct = transformation_matrix_90\n",
    "    elif(index_resultat == 2):\n",
    "        matrice_correct = transformation_matrix_180\n",
    "    elif(index_resultat == 3):\n",
    "        matrice_correct = transformation_matrix_270\n",
    "        \n",
    "    print(matrice_correct)\n",
    "    \n",
    "    T_x = matrice_correct[0,2]\n",
    "    T_y = matrice_correct[1,2]\n",
    "    rot = - np.angle(matrice_correct[0,0]+matrice_correct[1,0]*1j)*180/np.pi\n",
    "    \n",
    "    if rot > 0 :\n",
    "        rot=rot-360\n",
    "    \n",
    "    L_y, L_x , L_z  = image0_frag.shape\n",
    "    \n",
    "    tx = -T_y + L_x*np.sin(rot*np.pi/180)/2 - L_y*np.cos(rot*np.pi/180)/2\n",
    "    ty = -T_x - L_x*np.cos(rot*np.pi/180)/2 - L_y*np.sin(rot*np.pi/180)/2\n",
    "    \n",
    "    \n",
    "    return tx, ty, rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd413e",
   "metadata": {},
   "source": [
    "## Choix de la fresque et type de fragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a142f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresque 0 : Leonardo-da-Vinci_Ultima-Cena_5193x2926\n",
      "Fresque 1 : Masolino_GuarigionestorpioeresurrezioneTabita_2112x1080\n",
      "Fresque 2 : Michelangelo_ThecreationofAdam_1707x775\n",
      "Fresque 3 : Perugino_Consegnadellechiavi_2347x1438\n",
      "Fresque 4 : Piero-della-Francesca_ExaltationoftheCross_1239x900\n",
      "Fragmentation 0 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_13.56.32\n",
      "Fragmentation 1 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_14.14.54\n",
      "Fragmentation 2 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_14.35.20\n",
      "Fragmentation 3 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_14.55.54\n",
      "Fragmentation 4 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_15.15.49\n",
      "Fragmentation 5 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_15.36.5\n",
      "Fragmentation 6 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_15.55.13\n",
      "Fragmentation 7 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_16.28.9\n",
      "Fragmentation 8 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_16.48.9\n",
      "Fragmentation 9 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_17.13.18\n",
      "Fragmentation 10 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_17.38.6\n",
      "Fragmentation 11 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_17.54.5\n",
      "Fragmentation 12 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_18.13.53\n",
      "Fragmentation 13 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_18.34.4\n",
      "Fragmentation 14 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_18.53.50\n",
      "Fragmentation 15 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_19.14.7\n",
      "Fragmentation 16 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_19.35.39\n",
      "Fragmentation 17 : Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_19.56.3\n",
      "C:\\projects\\SuperGluePretrainedNetwork\\Fresques\\Leonardo-da-Vinci_Ultima-Cena_5193x2926\\Leonardo-da-Vinci_Ultima-Cena_5193x2926_2019-2-28_13.56.32\n"
     ]
    }
   ],
   "source": [
    "path_fresques = \"C:\\projects\\SuperGluePretrainedNetwork\\Fresques\"\n",
    "fresques = [f for f in os.listdir(path_fresques) if os.path.isdir(os.path.join(path_fresques, f))]\n",
    "\n",
    "count_fresque = 0\n",
    "################## CHANGER ICI FRESQUE ##################\n",
    "choix_fresque = 0\n",
    "\n",
    "#print(os.listdir(path_fresques))\n",
    "\n",
    "for i in range(len(fresques)):    \n",
    "    print('Fresque {} : {}'.format(count_fresque,fresques[count_fresque]))\n",
    "    count_fresque += 1\n",
    "\n",
    "path_AllFragmentations = os.path.join(path_fresques,fresques[choix_fresque])\n",
    "AllFragmentations = [f for f in os.listdir(path_AllFragmentations) if os.path.isdir(os.path.join(path_AllFragmentations, f))]\n",
    "\n",
    "count_fragmentation = 0\n",
    "################## CHANGER ICI TYPE FRAMENTATION ##################\n",
    "choix_fragmentation = 0\n",
    "\n",
    "for i in range(len(AllFragmentations)):    \n",
    "    print('Fragmentation {} : {}'.format(count_fragmentation,AllFragmentations[count_fragmentation]))\n",
    "    count_fragmentation += 1\n",
    "    \n",
    "path_fragmentation = os.path.join(path_AllFragmentations,AllFragmentations[choix_fragmentation])\n",
    "print(path_fragmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c888a0",
   "metadata": {},
   "source": [
    "## Obtenir resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50911e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.18097785e-07  1.00000077e+00  1.41499980e+03]\n",
      " [-1.00000077e+00  4.18097785e-07  1.75500010e+03]]\n",
      "Translation : ( -1546.5001914473594 , -1623.4998830221748 )\n",
      "Rotation :  -270.00002395521994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/171786765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#print('MATRICE TRANSFORMATION DU FRAGMENT {} :'.format(id_fragment))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mTx_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTy_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrot_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_fragment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_PartieFresque\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresize_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_viz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msizeX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mresultat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_fragment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTx_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTy_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrot_hat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/1734787178.py\u001b[0m in \u001b[0;36mget_transformation\u001b[1;34m(image0_frag, image1_fre, device, resize, resize_float, do_viz, Tx, Ty, sizeX1)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mimage0_frag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage0_frag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0mrotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mtransformation_matrix_180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbr_matches_180\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnbr_inliers_180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbool_accompli_180\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrice_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage0_frag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage1_fre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresize_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_viz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msizeX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;31m#print('Transltation : (',T_x_180,',', T_y_180,')')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;31m#print('Rotation : ', rot_180)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13428/1734787178.py\u001b[0m in \u001b[0;36mget_matrice_transformation\u001b[1;34m(image0_frag, image1_fre, rotation, device, resize, resize_float, do_viz, Tx, Ty, sizeX1)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# Perform the matching.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minp1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mkpts0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkpts1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keypoints0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keypoints1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\models\\matching.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'keypoints1'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuperpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\models\\superpoint.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m# Shared Encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\SuperGluePretrainedNetwork\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 443\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process the file\n",
    "path_fragments = os.path.join(path_fragmentation,'frag_eroded')\n",
    "path_list_fragments = os.path.join(path_fragmentation,'fragments.txt')\n",
    "path_imageFresque = os.path.join(path_AllFragmentations,fresques[choix_fresque]+'.ppm')\n",
    "path_resultat = os.path.join(path_fragmentation,'resultat.csv')\n",
    "fichier = open(path_list_fragments, \"r\")\n",
    "text = fichier.read()\n",
    "data = text.split('\\n')\n",
    "image_fresque = np.array(Image.open(path_imageFresque))\n",
    "\n",
    "# Handle --cache logic.\n",
    "do_viz = False\n",
    "\n",
    "resultat = [['Id','Tx','Ty','Rotation']]\n",
    "\n",
    "for i in range(len(data)-1):\n",
    "    Tx_hat='Nan'\n",
    "    Ty_hat='Nan'\n",
    "    rot_hat='Nan'\n",
    "    \n",
    "    id_fragment = int(data[i].split(' ')[0])\n",
    "    Tx = int(data[i].split(' ')[1])\n",
    "    Ty = int(data[i].split(' ')[2])\n",
    "    rot = int(data[i].split(' ')[2])\n",
    "    \n",
    "    path = os.path.join(path_fragments,'frag_eroded_{}_color.ppm'.format(id_fragment))\n",
    "    image_fragment = np.array(Image.open(path))\n",
    "    sizeX1 = sizeY1 = int(np.mean(image_fragment.shape[0:2]))\n",
    "    \n",
    "    image_PartieFresque, sizeX1 = crop_image(image_fresque,Tx,Ty,sizeX1,sizeY1)        \n",
    "    \n",
    "    #print('MATRICE TRANSFORMATION DU FRAGMENT {} :'.format(id_fragment))\n",
    "    \n",
    "    Tx_hat, Ty_hat, rot_hat = get_transformation(image_fragment,image_PartieFresque,device,resize,resize_float,do_viz,Tx,Ty,sizeX1)   \n",
    "    \n",
    "    resultat.append([id_fragment,Tx_hat,Ty_hat,rot_hat])\n",
    "    \n",
    "    \n",
    "    if (Tx_hat != 'Nan' and Ty_hat != 'Nan'and rot_hat != 'Nan'):\n",
    "        print('Translation : (',Tx_hat,',', Ty_hat,')')\n",
    "        print('Rotation : ', rot_hat)\n",
    "        \n",
    "with open(path_resultat, 'w', newline='') as student_file:\n",
    "    writer = csv.writer(student_file)\n",
    "    for i in resultat:        \n",
    "        writer.writerow(i)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47443798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
